var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __decorateClass = (decorators, target, key, kind) => {
  var result = kind > 1 ? void 0 : kind ? __getOwnPropDesc(target, key) : target;
  for (var i = decorators.length - 1, decorator; i >= 0; i--)
    if (decorator = decorators[i])
      result = (kind ? decorator(target, key, result) : decorator(result)) || result;
  if (kind && result)
    __defProp(target, key, result);
  return result;
};

// packages/durable-objects/src/namespace.ts
import { createHash, webcrypto } from "crypto";
import { URL } from "url";
import {
  Request,
  Response,
  withImmutableHeaders,
  withInputGating
} from "@miniflare/core";
import { InputGate, OutputGate } from "@miniflare/shared";
import { Response as BaseResponse } from "undici";

// packages/durable-objects/src/plugin.ts
import assert3 from "assert";
import {
  MiniflareError,
  Option,
  OptionType,
  Plugin
} from "@miniflare/shared";

// packages/durable-objects/src/storage.ts
import assert2 from "assert";
import { deserialize, serialize } from "v8";
import {
  addAll as addAll2,
  runWithInputGateClosed,
  viewToArray,
  waitUntilOnOutputGate
} from "@miniflare/shared";

// packages/durable-objects/src/rwmutex.ts
var ReadWriteMutex = class {
  readLockCount = 0;
  writeLocked = false;
  readResolveQueue = [];
  writeResolveQueue = [];
  readLock() {
    if (this.writeResolveQueue.length === 0 && !this.writeLocked) {
      this.readLockCount++;
      return;
    }
    return new Promise((resolve) => this.readResolveQueue.push(resolve));
  }
  writeLock() {
    if (this.readLockCount === 0 && !this.writeLocked) {
      this.writeLocked = true;
      return;
    }
    return new Promise((resolve) => this.writeResolveQueue.push(resolve));
  }
  unlock() {
    if (this.readLockCount > 0)
      return;
    if (this.writeResolveQueue.length > 0) {
      this.writeLocked = true;
      return this.writeResolveQueue.shift()?.();
    }
    this.writeLocked = false;
    this.readLockCount += this.readResolveQueue.length;
    for (const resolve of this.readResolveQueue)
      resolve();
    this.readResolveQueue.splice(0, this.readResolveQueue.length);
  }
  async runWithRead(closure) {
    const acquireAwaitable = this.readLock();
    if (acquireAwaitable instanceof Promise)
      await acquireAwaitable;
    try {
      const awaitable = closure();
      if (awaitable instanceof Promise)
        return await awaitable;
      return awaitable;
    } finally {
      this.readLockCount--;
      this.unlock();
    }
  }
  async runWithWrite(closure) {
    const acquirePromise = this.writeLock();
    if (acquirePromise instanceof Promise)
      await acquirePromise;
    try {
      const awaitable = closure();
      if (awaitable instanceof Promise)
        return await awaitable;
      return awaitable;
    } finally {
      this.unlock();
    }
  }
};

// packages/durable-objects/src/shadow.ts
import assert from "assert";
import {
  Storage,
  addAll
} from "@miniflare/shared";
import { listFilterMatch } from "@miniflare/storage-memory";
var collator = new Intl.Collator();
var ShadowStorage = class extends Storage {
  constructor(inner, recordReads = true) {
    super();
    this.inner = inner;
    if (recordReads)
      this.readSet = new Set();
  }
  readSet;
  copies = new Map();
  async has(key) {
    return await this.hasMany([key]) > 0;
  }
  async hasMany(keys) {
    if (this.readSet)
      addAll(this.readSet, keys);
    if (this.copies.size === 0)
      return this.inner.hasMany(keys);
    let count = 0;
    const innerHasKeys = [];
    for (const key of keys) {
      if (this.copies.has(key)) {
        if (this.copies.get(key) !== void 0)
          count++;
      } else {
        innerHasKeys.push(key);
      }
    }
    count += await this.inner.hasMany(innerHasKeys);
    return count;
  }
  async get(key) {
    return (await this.getMany([key]))[0];
  }
  async getMany(keys) {
    if (this.readSet)
      addAll(this.readSet, keys);
    if (this.copies.size === 0)
      return this.inner.getMany(keys, true);
    const result = new Array(keys.length);
    const innerGetKeys = [];
    const innerGetIndices = [];
    for (let i = 0; i < keys.length; i++) {
      const key = keys[i];
      if (this.copies.has(key)) {
        const copy = this.copies.get(key);
        result[i] = copy && { value: copy.value.slice() };
      } else {
        innerGetKeys.push(key);
        innerGetIndices.push(i);
      }
    }
    assert.strictEqual(innerGetKeys.length, innerGetIndices.length);
    if (innerGetKeys.length === 0)
      return result;
    const innerGetResult = await this.inner.getMany(innerGetKeys, true);
    assert.strictEqual(innerGetKeys.length, innerGetResult.length);
    for (let i = 0; i < innerGetKeys.length; i++) {
      result[innerGetIndices[i]] = innerGetResult[i];
    }
    return result;
  }
  put(key, value) {
    this.copies.set(key, { value: value.value.slice() });
  }
  async delete(key) {
    return await this.deleteMany([key]) > 0;
  }
  async deleteMany(keys) {
    const deleted = await this.hasMany(keys);
    for (const key of keys)
      this.copies.set(key, void 0);
    return deleted;
  }
  async list(options) {
    if (this.copies.size === 0) {
      const { keys: keys2 } = await this.inner.list(options, true);
      if (this.readSet) {
        addAll(this.readSet, keys2.map(({ name }) => name));
      }
      return { keys: keys2, cursor: "" };
    }
    const matchingCopies = new Map();
    let deletedMatchingCopies = 0;
    for (const [key, value] of this.copies.entries()) {
      if (listFilterMatch(options, key)) {
        matchingCopies.set(key, value);
        if (value === void 0)
          deletedMatchingCopies++;
      }
    }
    let { keys } = await this.inner.list({
      ...options,
      limit: options?.limit && options.limit + deletedMatchingCopies
    }, true);
    keys = keys.filter((stored) => {
      if (matchingCopies.has(stored.name)) {
        const matching = matchingCopies.get(stored.name);
        matchingCopies.delete(stored.name);
        if (matching === void 0)
          return false;
      }
      return true;
    });
    for (const [key, value] of matchingCopies.entries()) {
      if (value)
        keys.push({ name: key });
    }
    const direction = options?.reverse ? -1 : 1;
    keys.sort((a, b) => direction * collator.compare(a.name, b.name));
    if (options?.limit)
      keys = keys.slice(0, options.limit);
    if (this.readSet) {
      addAll(this.readSet, keys.map(({ name }) => name));
    }
    return { keys, cursor: "" };
  }
};

// packages/durable-objects/src/storage.ts
var MAX_KEYS = 128;
var MAX_KEY_SIZE = 2048;
var MAX_VALUE_SIZE = 32 * 1024;
var ENFORCED_MAX_VALUE_SIZE = MAX_VALUE_SIZE + 32;
var undefinedKeyError = ": parameter 1 is not of type 'variant'. (key is undefined)";
function intersects(a, b) {
  for (const value of a)
    if (b.has(value))
      return true;
  return false;
}
function assertKeySize(key, many = false) {
  if (Buffer.byteLength(key) <= MAX_KEY_SIZE)
    return;
  if (many) {
    throw new RangeError(`Key "${key}" is larger than the limit of ${MAX_KEY_SIZE} bytes.`);
  }
  throw new RangeError(`Keys cannot be larger than ${MAX_KEY_SIZE} bytes.`);
}
function assertValueSize(value, key) {
  if (value.byteLength <= ENFORCED_MAX_VALUE_SIZE)
    return;
  if (key !== void 0) {
    throw new RangeError(`Value for key "${key}" is above the limit of ${MAX_VALUE_SIZE} bytes.`);
  }
  throw new RangeError(`Values cannot be larger than ${MAX_VALUE_SIZE} bytes.`);
}
async function get(storage, keys) {
  if (Array.isArray(keys)) {
    if (keys.length > MAX_KEYS) {
      throw new RangeError(`Maximum number of keys is ${MAX_KEYS}.`);
    }
    const defined = [];
    for (const key of keys) {
      if (key === void 0)
        continue;
      defined.push(key);
      assertKeySize(key, true);
    }
    const res = new Map();
    const values = await storage.getMany(defined);
    assert2.strictEqual(defined.length, values.length);
    for (let i = 0; i < defined.length; i++) {
      const value2 = values[i];
      if (value2 !== void 0)
        res.set(defined[i], deserialize(value2.value));
    }
    return res;
  }
  assertKeySize(keys);
  const value = await storage.get(keys);
  return value && deserialize(value.value);
}
async function list(storage, options = {}) {
  if (options.limit !== void 0 && options.limit <= 0) {
    throw new TypeError("List limit must be positive.");
  }
  const { keys } = await storage.list(options);
  return get(storage, keys.map(({ name }) => name));
}
function normalisePutEntries(keyEntries, valueOptions) {
  if (typeof keyEntries === "string") {
    assertKeySize(keyEntries);
    if (valueOptions === void 0) {
      throw new TypeError("put() called with undefined value.");
    }
    const serialized = serialize(valueOptions);
    assertValueSize(serialized);
    return [[keyEntries, { value: viewToArray(serialized) }]];
  }
  const entries = Object.entries(keyEntries);
  if (entries.length > MAX_KEYS) {
    throw new RangeError(`Maximum number of pairs is ${MAX_KEYS}.`);
  }
  const result = [];
  for (const [key, rawValue] of entries) {
    assertKeySize(key, true);
    if (rawValue === void 0)
      continue;
    const serialized = serialize(rawValue);
    assertValueSize(serialized, key);
    result.push([key, { value: viewToArray(serialized) }]);
  }
  return result;
}
function normaliseDeleteKeys(keys) {
  if (Array.isArray(keys)) {
    if (keys.length > MAX_KEYS) {
      throw new RangeError(`Maximum number of keys is ${MAX_KEYS}.`);
    }
    const defined = [];
    for (const key of keys) {
      if (key === void 0)
        continue;
      assertKeySize(key, true);
      defined.push(key);
    }
    return defined;
  } else {
    assertKeySize(keys);
    return [keys];
  }
}
var kInner = Symbol("kInner");
var kStartTxnCount = Symbol("kStartTxnCount");
var kRolledback = Symbol("kRolledback");
var kCommitted = Symbol("kCommitted");
var kWriteSet = Symbol("kWriteSet");
var DurableObjectTransaction = class {
  [kInner];
  [kStartTxnCount];
  [kRolledback] = false;
  [kCommitted] = false;
  [kWriteSet] = new Set();
  constructor(inner, startTxnCount) {
    this[kInner] = new ShadowStorage(inner);
    this[kStartTxnCount] = startTxnCount;
  }
  #check(op) {
    if (this[kRolledback]) {
      throw new Error(`Cannot ${op}() on rolled back transaction`);
    }
    if (this[kCommitted]) {
      throw new Error(`Cannot call ${op}() on transaction that has already committed: did you move \`txn\` outside of the closure?`);
    }
  }
  #markWritten(...keys) {
    addAll2(this[kWriteSet], keys);
    if (this[kWriteSet].size > MAX_KEYS) {
      throw new Error(`Maximum number of keys modified in a transaction is ${MAX_KEYS}.`);
    }
  }
  get(keys, options) {
    if (keys === void 0) {
      throw new TypeError("Failed to execute 'get' on 'DurableObjectTransaction'" + undefinedKeyError);
    }
    this.#check("get");
    return runWithInputGateClosed(() => get(this[kInner], keys), options?.allowConcurrency);
  }
  #put(keyEntries, valueOptions) {
    const entries = normalisePutEntries(keyEntries, valueOptions);
    this.#markWritten(...entries.map(([key]) => key));
    return this[kInner].putMany(entries);
  }
  put(keyEntries, valueOptions, options) {
    if (keyEntries === void 0) {
      throw new TypeError("Failed to execute 'put' on 'DurableObjectTransaction'" + undefinedKeyError);
    }
    this.#check("put");
    if (!options && typeof keyEntries !== "string")
      options = valueOptions;
    return waitUntilOnOutputGate(runWithInputGateClosed(() => this.#put(keyEntries, valueOptions), options?.allowConcurrency), options?.allowUnconfirmed);
  }
  #delete(keys) {
    const keysIsArray = Array.isArray(keys);
    keys = normaliseDeleteKeys(keys);
    this.#markWritten(...keys);
    return keysIsArray ? this[kInner].deleteMany(keys) : Promise.resolve(this[kInner].delete(keys[0]));
  }
  delete(keys, options) {
    if (keys === void 0) {
      throw new TypeError("Failed to execute 'delete' on 'DurableObjectTransaction'" + undefinedKeyError);
    }
    this.#check("delete");
    return waitUntilOnOutputGate(runWithInputGateClosed(() => this.#delete(keys), options?.allowConcurrency), options?.allowUnconfirmed);
  }
  deleteAll() {
    throw new Error("Cannot call deleteAll() within a transaction");
  }
  list(options = {}) {
    this.#check("list");
    return runWithInputGateClosed(() => list(this[kInner], options), options.allowConcurrency);
  }
  rollback() {
    if (this[kRolledback])
      return;
    this.#check("rollback");
    this[kRolledback] = true;
  }
};
var txnWriteSetsMaxSize = 16;
function runWithGatesClosed(closure, options) {
  return waitUntilOnOutputGate(runWithInputGateClosed(closure, options?.allowConcurrency), options?.allowUnconfirmed);
}
var DurableObjectStorage = class {
  #mutex = new ReadWriteMutex();
  #txnCount = 0;
  #txnWriteSets = new Map();
  #deletedKeySets = [];
  #deletedKeyResults = new Map();
  #inner;
  #shadow;
  constructor(inner) {
    this.#inner = inner;
    this.#shadow = new ShadowStorage(inner, false);
  }
  async #txnRead(closure) {
    const startTxnCount = this.#txnCount;
    const txn = new DurableObjectTransaction(this.#shadow, startTxnCount);
    const result = await closure(txn);
    txn[kCommitted] = true;
    return { txn, result };
  }
  async #txnValidateWrite(txn) {
    if (txn[kRolledback])
      return true;
    return this.#mutex.runWithWrite(async () => {
      const finishTxnCount = this.#txnCount;
      const readSet = txn[kInner].readSet;
      for (let t = txn[kStartTxnCount] + 1; t <= finishTxnCount; t++) {
        const otherWriteSet = await this.#txnWriteSets.get(t);
        if (!otherWriteSet || intersects(otherWriteSet, readSet)) {
          return false;
        }
      }
      this.#txnRecordWriteSet(txn[kWriteSet]);
      for (const [key, value] of txn[kInner].copies.entries()) {
        this.#shadow.copies.set(key, value);
      }
      await this.#flush();
      return true;
    });
  }
  #txnRecordWriteSet(writeSet) {
    this.#txnCount++;
    this.#txnWriteSets.set(this.#txnCount, writeSet);
    this.#txnWriteSets.delete(this.#txnCount - txnWriteSetsMaxSize);
  }
  transaction(closure) {
    return runWithGatesClosed(async () => {
      while (true) {
        const { txn, result } = await this.#txnRead(closure);
        if (await this.#txnValidateWrite(txn))
          return result;
      }
    });
  }
  async get(keys, options) {
    if (keys === void 0) {
      throw new TypeError("Failed to execute 'get' on 'DurableObjectStorage'" + undefinedKeyError);
    }
    return runWithInputGateClosed(() => this.#mutex.runWithRead(() => get(this.#shadow, keys)), options?.allowConcurrency);
  }
  #flush = async () => {
    if (this.#shadow.copies.size === 0) {
      assert2.strictEqual(this.#deletedKeySets.length, 0);
      return;
    }
    const deletedKeySets = this.#deletedKeySets;
    this.#deletedKeySets = [];
    const entries = [...this.#shadow.copies.entries()];
    const allDeletedKeys = new Set();
    for (const deleteKeySet of deletedKeySets) {
      const result = await this.#inner.deleteMany(deleteKeySet);
      this.#deletedKeyResults.set(deleteKeySet, result);
      addAll2(allDeletedKeys, deleteKeySet);
    }
    const putEntries = [];
    const deleteKeys = [];
    for (const [key, value] of entries) {
      if (value)
        putEntries.push([key, value]);
      else if (!allDeletedKeys.has(key))
        deleteKeys.push(key);
    }
    if (putEntries.length > 0)
      await this.#inner.putMany(putEntries);
    if (deleteKeys.length > 0)
      await this.#inner.deleteMany(deleteKeys);
    for (const [key, value] of entries) {
      if (this.#shadow.copies.get(key) === value) {
        this.#shadow.copies.delete(key);
      }
    }
  };
  put(keyEntries, valueOptions, options) {
    if (keyEntries === void 0) {
      throw new TypeError("Failed to execute 'put' on 'DurableObjectStorage'" + undefinedKeyError);
    }
    const entries = normalisePutEntries(keyEntries, valueOptions);
    if (!options && typeof keyEntries !== "string")
      options = valueOptions;
    return runWithGatesClosed(async () => {
      await this.#mutex.runWithWrite(() => {
        for (const [key, value] of entries)
          this.#shadow.put(key, value);
        this.#txnRecordWriteSet(new Set(entries.map(([key]) => key)));
      });
      await Promise.resolve();
      return this.#mutex.runWithWrite(this.#flush);
    }, options);
  }
  delete(keys, options) {
    if (keys === void 0) {
      throw new TypeError("Failed to execute 'delete' on 'DurableObjectStorage'" + undefinedKeyError);
    }
    const keysIsArray = Array.isArray(keys);
    keys = normaliseDeleteKeys(keys);
    let deleted = 0;
    const deletedKeySet = [];
    return runWithGatesClosed(async () => {
      await this.#mutex.runWithWrite(() => {
        for (const key of keys) {
          if (key === void 0)
            continue;
          if (this.#shadow.copies.has(key)) {
            if (this.#shadow.copies.get(key) !== void 0) {
              deleted++;
            }
          } else {
            deletedKeySet.push(key);
          }
          this.#shadow.copies.set(key, void 0);
        }
        if (deletedKeySet.length)
          this.#deletedKeySets.push(deletedKeySet);
        this.#txnRecordWriteSet(new Set(keys));
      });
      await Promise.resolve();
      return this.#mutex.runWithWrite(async () => {
        await this.#flush();
        if (deletedKeySet.length) {
          assert2(!this.#deletedKeySets.includes(deletedKeySet));
          const result = this.#deletedKeyResults.get(deletedKeySet);
          this.#deletedKeyResults.delete(deletedKeySet);
          assert2(result !== void 0);
          deleted += result;
        }
        return keysIsArray ? deleted : deleted > 0;
      });
    }, options);
  }
  async deleteAll(options) {
    return runWithGatesClosed(() => this.#mutex.runWithWrite(async () => {
      const { keys } = await this.#shadow.list();
      const names = keys.map(({ name }) => name);
      for (const key of names)
        this.#shadow.copies.set(key, void 0);
      this.#txnRecordWriteSet(new Set(names));
      await this.#flush();
    }), options);
  }
  async list(options) {
    return runWithInputGateClosed(() => this.#mutex.runWithRead(() => list(this.#shadow, options)), options?.allowConcurrency);
  }
};

// packages/durable-objects/src/plugin.ts
var DurableObjectError = class extends MiniflareError {
};
var DurableObjectsPlugin = class extends Plugin {
  durableObjects;
  durableObjectsPersist;
  #processedObjects;
  #requireFullUrl;
  #contextPromise;
  #contextResolve;
  #constructors = new Map();
  #bindings = {};
  #objects = new Map();
  constructor(ctx, options) {
    super(ctx);
    this.assignOptions(options);
    this.#processedObjects = Object.entries(this.durableObjects ?? {}).map(([name, options2]) => {
      const className = typeof options2 === "object" ? options2.className : options2;
      const scriptName = typeof options2 === "object" ? options2.scriptName : void 0;
      return { name, className, scriptName };
    });
    this.#requireFullUrl = ctx.compat.isEnabled("durable_object_fetch_requires_full_url");
  }
  async getObject(storage, id) {
    assert3(this.#contextPromise, "beforeReload() must be called before getObject()");
    await this.#contextPromise;
    const objectName = id[kObjectName];
    const key = `${objectName}:${id.toString()}`;
    let statePromise = this.#objects.get(key);
    if (statePromise)
      return statePromise;
    statePromise = (async () => {
      const objectStorage = new DurableObjectStorage(await storage.storage(key, this.durableObjectsPersist));
      const state = new DurableObjectState(id, objectStorage);
      const constructor = this.#constructors.get(objectName);
      assert3(constructor);
      state[kInstance] = new constructor(state, this.#bindings);
      return state;
    })();
    this.#objects.set(key, statePromise);
    return statePromise;
  }
  getNamespace(storage, objectName) {
    const factory = (id) => this.getObject(storage, id);
    return new DurableObjectNamespace(objectName, factory, this.#requireFullUrl);
  }
  setup(storageFactory) {
    const bindings = {};
    for (const { name } of this.#processedObjects) {
      bindings[name] = this.getNamespace(storageFactory, name);
    }
    return {
      bindings,
      requiresModuleExports: this.#processedObjects.length > 0
    };
  }
  beforeReload() {
    this.#objects.clear();
    this.#contextPromise = new Promise((resolve) => this.#contextResolve = resolve);
  }
  reload(bindings, moduleExports, mountedModuleExports) {
    this.#constructors.clear();
    for (const { name, className, scriptName } of this.#processedObjects) {
      let constructor;
      if (scriptName === void 0) {
        constructor = moduleExports[className];
      } else {
        const scriptExports = mountedModuleExports[scriptName];
        if (!scriptExports) {
          throw new DurableObjectError("ERR_SCRIPT_NOT_FOUND", `Script ${scriptName} for Durable Object ${name} not found`);
        }
        constructor = scriptExports[className];
      }
      if (constructor) {
        this.#constructors.set(name, constructor);
      } else {
        const script = scriptName ? ` in script ${scriptName}` : "";
        throw new DurableObjectError("ERR_CLASS_NOT_FOUND", `Class ${className}${script} for Durable Object ${name} not found`);
      }
    }
    this.#bindings = bindings;
    assert3(this.#contextResolve, "beforeReload() must be called before reload()");
    this.#contextResolve();
  }
  dispose() {
    return this.beforeReload();
  }
};
__decorateClass([
  Option({
    type: OptionType.OBJECT,
    typeFormat: "NAME=CLASS",
    name: "do",
    alias: "o",
    description: "Durable Object to bind",
    fromWrangler: ({ durable_objects }) => durable_objects?.bindings?.reduce((objects, { name, class_name, script_name }) => {
      objects[name] = { className: class_name, scriptName: script_name };
      return objects;
    }, {})
  })
], DurableObjectsPlugin.prototype, "durableObjects", 2);
__decorateClass([
  Option({
    type: OptionType.BOOLEAN_STRING,
    name: "do-persist",
    description: "Persist Durable Object data (to optional path)",
    logName: "Durable Objects Persistence",
    fromWrangler: ({ miniflare }) => miniflare?.durable_objects_persist
  })
], DurableObjectsPlugin.prototype, "durableObjectsPersist", 2);

// packages/durable-objects/src/namespace.ts
function hexEncode(value) {
  return Array.from(value).map((byte) => byte.toString(16).padStart(2, "0")).join("");
}
var kObjectName = Symbol("kObjectName");
var DurableObjectId2 = class {
  constructor(objectName, hexId, name) {
    this.name = name;
    this[kObjectName] = objectName;
    this.#hexId = hexId;
  }
  [kObjectName];
  #hexId;
  equals(other) {
    if (!(other instanceof DurableObjectId2))
      return false;
    return this.#hexId === other.#hexId;
  }
  toString() {
    return this.#hexId;
  }
};
var kInstance = Symbol("kInstance");
var kFetch = Symbol("kFetch");
var DurableObjectState = class {
  constructor(id, storage) {
    this.id = id;
    this.storage = storage;
  }
  #inputGate = new InputGate();
  [kInstance];
  waitUntil(_promise) {
  }
  blockConcurrencyWhile(closure) {
    return this.#inputGate.runWithClosed(closure);
  }
  [kFetch](request) {
    const outputGate = new OutputGate();
    return outputGate.runWith(() => this.#inputGate.runWith(() => this[kInstance].fetch(request)));
  }
};
var DurableObjectStub = class {
  constructor(factory, id, requireFullUrl) {
    this.id = id;
    this.#factory = factory;
    this.#requireFullUrl = requireFullUrl;
  }
  #factory;
  #requireFullUrl;
  get name() {
    return this.id.name;
  }
  async fetch(input, init) {
    const state = await this.#factory(this.id);
    if (!this.#requireFullUrl && typeof input === "string") {
      input = new URL(input, "https://fake-host");
    }
    const request = input instanceof Request && !init ? input : new Request(input, init);
    const res = await state[kFetch](withInputGating(withImmutableHeaders(request)));
    const validRes = res instanceof Response || res instanceof BaseResponse;
    if (!validRes) {
      throw new DurableObjectError("ERR_RESPONSE_TYPE", "Durable Object fetch handler didn't respond with a Response object");
    }
    return res;
  }
};
var HEX_ID_REGEXP = /^[A-Za-z0-9]{64}$/;
var DurableObjectNamespace = class {
  #objectName;
  #factory;
  #objectNameHash;
  #objectNameHashHex;
  #requireFullUrl;
  constructor(objectName, factory, requireFullUrl) {
    this.#objectName = objectName;
    this.#factory = factory;
    this.#objectNameHash = createHash("sha256").update(this.#objectName).digest().slice(0, 8);
    this.#objectNameHashHex = hexEncode(this.#objectNameHash);
    this.#requireFullUrl = requireFullUrl;
  }
  newUniqueId(_options) {
    const id = new Uint8Array(32);
    const view = new DataView(id.buffer);
    view.setBigUint64(1, BigInt(Date.now()));
    webcrypto.getRandomValues(new DataView(id.buffer, 9, 15));
    id.set(this.#objectNameHash, 24);
    return new DurableObjectId2(this.#objectName, hexEncode(id));
  }
  idFromName(name) {
    const id = createHash("sha256").update(this.#objectName).update(name).digest();
    id[0] |= 128;
    id.set(this.#objectNameHash, 24);
    return new DurableObjectId2(this.#objectName, hexEncode(id), name);
  }
  idFromString(hexId) {
    if (!HEX_ID_REGEXP.test(hexId)) {
      throw new TypeError("Invalid Durable Object ID. Durable Object IDs must be 64 hex digits.");
    }
    if (!hexId.endsWith(this.#objectNameHashHex)) {
      throw new TypeError("Invalid Durable Object ID. The ID does not match this Durable Object class.");
    }
    return new DurableObjectId2(this.#objectName, hexId.toLowerCase());
  }
  get(id) {
    if (id[kObjectName] !== this.#objectName || !id.toString().endsWith(this.#objectNameHashHex)) {
      throw new TypeError("ID is not for this Durable Object class.");
    }
    return new DurableObjectStub(this.#factory, id, this.#requireFullUrl);
  }
};
export {
  DurableObjectError,
  DurableObjectId2 as DurableObjectId,
  DurableObjectNamespace,
  DurableObjectState,
  DurableObjectStorage,
  DurableObjectStub,
  DurableObjectTransaction,
  DurableObjectsPlugin,
  ReadWriteMutex,
  ShadowStorage
};
//# sourceMappingURL=index.js.map
